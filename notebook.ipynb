{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/soumitrapy/templatecv.git project\n",
    "# %cd project\n",
    "# !wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
    "# !unzip nature_12K.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3e977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import yaml\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader, random_split\n",
    "\n",
    "from torchvision import transforms\n",
    "#from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8b8420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'templatecv',\n",
       " 'use_wandb': True,\n",
       " 'dataset': {'name': 'CustomDataset',\n",
       "  'path': './data/inaturalist_12K/',\n",
       "  'img_size': 256,\n",
       "  'class_names': ['Plantae',\n",
       "   'Mammalia',\n",
       "   'Animalia',\n",
       "   'Reptilia',\n",
       "   'Amphibia',\n",
       "   'Aves',\n",
       "   'Fungi',\n",
       "   'Arachnida',\n",
       "   'Mollusca',\n",
       "   'Insecta'],\n",
       "  'batch_size': 5},\n",
       " 'model': {'name': 'defaultmodel',\n",
       "  'in_channels': 3,\n",
       "  'num_classes': 10,\n",
       "  'filters': 4,\n",
       "  'kernel_size': 3,\n",
       "  'dense_neurons': 100},\n",
       " 'train': {'epochs': 2, 'val_interval': 2}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "config = yaml.safe_load(open(\"config/default.yaml\"))\n",
    "#config = yaml.safe_load(open(\"config/pretrained.yaml\"))\n",
    "#config = yaml.safe_load(open(\"config/smallcnn.yaml\"))\n",
    "\n",
    "# config['dataset']['batch_size']=32\n",
    "# config['train']['epochs']=1\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499ece3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msoumitrapy\u001b[0m (\u001b[33msoumitrapy-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "if config.get('use_wandb',False):\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb0e086",
   "metadata": {},
   "source": [
    "### DataLoader Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1245ca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 9999, val len: 2000\n",
      "device = cpu\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import CustomDataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "cfg = config['dataset']\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(cfg['img_size']),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(cfg['img_size']),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "splits = ['train', 'val']\n",
    "datasets = {x:CustomDataset(path= cfg['path']+x,\n",
    "                            class_names=cfg['class_names'],\n",
    "                            transform=data_transforms[x])\n",
    "            for x in splits}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x],\n",
    "                                              batch_size=cfg['batch_size'],\n",
    "                                              shuffle=True\n",
    "                                              )\n",
    "                for x in splits}\n",
    "\n",
    "class_names = datasets['train'].class_names\n",
    "print(f\"train len: {len(datasets['train'])}, val len: {len(datasets['val'])}\")\n",
    "\n",
    "# We want to be able to train our model on an `accelerator <https://pytorch.org/docs/stable/torch.html#accelerators>`__\n",
    "# such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available, we will use it. Otherwise, we use the CPU.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd01199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform = transforms.Compose([\n",
    "# #         transforms.Resize(tuple(config['dataset']['img_size'])),\n",
    "# #         transforms.ToTensor()\n",
    "# #     ])\n",
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "#         transforms.RandomResizedCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "# target_transform = None\n",
    "# train_path = config['dataset']['path']+\"train\"\n",
    "# test_path = config['dataset']['path']+\"val\"\n",
    "\n",
    "# trainds = CustomDataset(path=train_path,\n",
    "#                         class_names=config['dataset']['class_names'],\n",
    "#                         transform=data_transforms['train'],\n",
    "#                         target_transform=target_transform\n",
    "#                         )\n",
    "\n",
    "# val_split = int(0.2 * len(trainds))\n",
    "# trainds, valds = random_split(trainds, [len(trainds) - val_split, val_split])\n",
    "# testds = CustomDataset(path=test_path,\n",
    "#                         class_names=config['dataset']['class_names'],\n",
    "#                         transform=data_transforms['val'],\n",
    "#                         target_transform=target_transform\n",
    "#                         )\n",
    "# traindl = DataLoader(trainds, batch_size=config['dataset']['batch_size'])\n",
    "# valdl = DataLoader(valds, batch_size=config['dataset']['batch_size'])\n",
    "# testdl = DataLoader(testds, batch_size=config['dataset']['batch_size'])\n",
    "# print(len(trainds), len(valds), len(testds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2213598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 256, 256]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataloaders['train']:\n",
    "    print(x.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1254d9c0",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5365b7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import DefaultModel\n",
    "#from models.smallcnncnn import SmallCNN\n",
    "\n",
    "cfg = config['model']\n",
    "model = DefaultModel(cfg)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87e80a",
   "metadata": {},
   "source": [
    "### Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c89927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pretrained import get_model\n",
    "model = get_model(config['model'])\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4124940",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b223be",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27827cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/po/Documents/sources/templatecv/wandb/run-20250421_011940-vyfgt57v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/soumitrapy-iit-madras/templatecv/runs/vyfgt57v' target=\"_blank\">DefaultModel21 01:19:4</a></strong> to <a href='https://wandb.ai/soumitrapy-iit-madras/templatecv' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/soumitrapy-iit-madras/templatecv' target=\"_blank\">https://wandb.ai/soumitrapy-iit-madras/templatecv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/soumitrapy-iit-madras/templatecv/runs/vyfgt57v' target=\"_blank\">https://wandb.ai/soumitrapy-iit-madras/templatecv/runs/vyfgt57v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25%|██▌       | 507/2000 [02:11<06:25,  3.87it/s, train_accuracy=15.5, train_loss=3.49]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[33m'\u001b[39m\u001b[33muse_wandb\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m      4\u001b[39m     wandb.init(\n\u001b[32m      5\u001b[39m         project=config[\u001b[33m'\u001b[39m\u001b[33mproject\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      6\u001b[39m         name = \u001b[38;5;28mtype\u001b[39m(model).\u001b[34m__name__\u001b[39m+\u001b[38;5;28mstr\u001b[39m(datetime.now())[\u001b[32m8\u001b[39m:\u001b[32m18\u001b[39m],\n\u001b[32m      7\u001b[39m         config=config[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      8\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muse_wandb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/sources/templatecv/train.py:88\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, loss_fn, dataloaders, config, model_config, scheduler, device, use_wandb)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m     87\u001b[39m     model.train()\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     train_loss, train_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_wandb:\n\u001b[32m     90\u001b[39m         wandb.log({\u001b[33m\"\u001b[39m\u001b[33mtrain/train_loss\u001b[39m\u001b[33m\"\u001b[39m: train_loss, \u001b[33m\"\u001b[39m\u001b[33mtrain/train_accuracy\u001b[39m\u001b[33m\"\u001b[39m: train_acc}, step=epoch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/sources/templatecv/train.py:15\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, dl, optimizer, loss_fn, epoch, device)\u001b[39m\n\u001b[32m     13\u001b[39m correct, total  = \u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m\n\u001b[32m     14\u001b[39m pbar = tqdm(dl,desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/sources/templatecv/preprocessing.py:38\u001b[39m, in \u001b[36mCustomDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     image = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRGB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     label = \u001b[38;5;28mself\u001b[39m.labels[index]\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/PIL/Image.py:993\u001b[39m, in \u001b[36mImage.convert\u001b[39m\u001b[34m(self, mode, matrix, dither, palette, colors)\u001b[39m\n\u001b[32m    990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mBGR;15\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBGR;24\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    991\u001b[39m     deprecate(mode, \u001b[32m12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m993\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    995\u001b[39m has_transparency = \u001b[33m\"\u001b[39m\u001b[33mtransparency\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    997\u001b[39m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/PIL/ImageFile.py:280\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m         s = \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecodermaxblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, struct.error) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    282\u001b[39m         \u001b[38;5;66;03m# truncated png/gif\u001b[39;00m\n\u001b[32m    283\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m LOAD_TRUNCATED_IMAGES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/PIL/JpegImagePlugin.py:404\u001b[39m, in \u001b[36mJpegImageFile.load_read\u001b[39m\u001b[34m(self, read_bytes)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mload_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, read_bytes: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28mbytes\u001b[39m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[33;03m    internal: read more image data\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[33;03m    For premature EOF and LOAD_TRUNCATED_IMAGES adds EOI marker\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[33;03m    so libjpeg can finish decoding\u001b[39;00m\n\u001b[32m    403\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m ImageFile.LOAD_TRUNCATED_IMAGES \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_ended\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    407\u001b[39m         \u001b[38;5;66;03m# Premature EOF.\u001b[39;00m\n\u001b[32m    408\u001b[39m         \u001b[38;5;66;03m# Pretend file is finished adding EOI marker\u001b[39;00m\n\u001b[32m    409\u001b[39m         \u001b[38;5;28mself\u001b[39m._ended = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "ru = None\n",
    "if config['use_wandb']:\n",
    "    wandb.init(\n",
    "        project=config['project'],\n",
    "        name = type(model).__name__+str(datetime.now())[8:18],\n",
    "        config=config['model'],\n",
    "    )\n",
    "train(model=model, optimizer=optimizer, loss_fn=loss_fn, dataloaders=dataloaders,config=config['train'], model_config=config['model'], scheduler = scheduler, device = device, use_wandb = config['use_wandb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813fe4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = run.use_artifact(\"trained-model:latest\")\n",
    "model_dir = model_artifact.download()\n",
    "model_path = os.path.join(model_dir, \"trained_model.pt\")\n",
    "model_config = model_artifact.metadata\n",
    "\n",
    "model = DefaultModel(**model_config)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "\n",
    "    loss, accuracy, highest_losses, hardest_examples, true_labels, preds = evaluate(model, test_loader)\n",
    "\n",
    "    run.summary.update({\"loss\": loss, \"accuracy\": accuracy})\n",
    "\n",
    "    wandb.log({\"high-loss-examples\":\n",
    "        [wandb.Image(hard_example, caption=str(int(pred)) + \",\" +  str(int(label)))\n",
    "            for hard_example, pred, label in zip(hardest_examples, preds, true_labels)]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8214f",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = './checkpoints/ResNet_cuda2025-04-19 17_1.pth'\n",
    "# model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696a4db",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55431b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import visualize_model\n",
    "visualize_model(model,valdl, class_names, 100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0e141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e774b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
